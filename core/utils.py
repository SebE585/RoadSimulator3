"""
utils.py
Utilitaires g√©n√©riques pour la validation et l'export CSV dans RoadSimulator3
"""

import pandas as pd
import numpy as np
import os
import warnings
def deprecated(func):
    """
    D√©corateur pour marquer une fonction comme obsol√®te.
    Affiche un avertissement √† l'ex√©cution.
    """
    def wrapper(*args, **kwargs):
        warnings.warn(f"[DEPRECATED] La fonction '{func.__name__}' est obsol√®te.", DeprecationWarning, stacklevel=2)
        return func(*args, **kwargs)
    return wrapper


def ensure_event_column_object(df):
    """
    Assure que la colonne 'event' existe et est de type object (pour accepter des cha√Ænes).
    """
    if 'event' not in df.columns:
        df['event'] = pd.Series(dtype='object')
    else:
        df['event'] = df['event'].astype('object')
    return df

@deprecated
def find_latest_trace(base_dir='data/simulations'):
    logger.warning("‚ö†Ô∏è Appel d'une fonction marqu√©e @deprecated.")
    """
    Recherche le dernier fichier trace.csv dans le r√©pertoire sp√©cifi√©.

    Args:
        base_dir (str): R√©pertoire racine contenant les sous-dossiers de simulation.

    Returns:
        str or None: Chemin complet vers le dernier trace.csv, ou None si absent.
    """
    if not os.path.exists(base_dir):
        return None
    out_dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]
    if not out_dirs:
        return None
    latest_dir = max(out_dirs, key=lambda d: os.path.getmtime(os.path.join(base_dir, d)))
    trace_path = os.path.join(base_dir, latest_dir, 'trace.csv')
    return trace_path if os.path.exists(trace_path) else None

CSV_COLUMNS = [
    'timestamp', 'lat', 'lon', 'altitude', 'speed', 
    'acc_x', 'acc_y', 'acc_z', 
    'gyro_x', 'gyro_y', 'gyro_z',
    'event', 'heading', 'sinuosity', 'curvature',
    'osm_highway', 'road_type', 'slope_percent'
]

def ensure_csv_column_order(df):
    """
    R√©ordonne le DataFrame selon l'ordre strict attendu pour l'export CSV.
    V√©rifie la pr√©sence de toutes les colonnes n√©cessaires, y compris les colonnes gyroscopiques.
    Ignore les colonnes en surplus.
    """
    missing = set(CSV_COLUMNS) - set(df.columns)
    if missing:
        raise ValueError(f"Colonnes manquantes avant export CSV : {missing}")
    return df[CSV_COLUMNS]


def export_csv(df, output_path):
    """
    Exporte le DataFrame au format CSV avec ordre des colonnes garanti.
    """
    df_ordered = ensure_csv_column_order(df)
    df_ordered.to_csv(output_path, index=False)
    print(f"‚úÖ CSV export√© avec succ√®s : {output_path}")

def load_trace(csv_path):
    """
    Charge un CSV de simulation en DataFrame avec parsing du timestamp.
    """
    df = pd.read_csv(csv_path, parse_dates=['timestamp'])
    return df

@deprecated
@deprecated
def get_log_path(log_type, timestamp, base_dir='data/simulations'):
    logger.warning("‚ö†Ô∏è Appel d'une fonction marqu√©e @deprecated.")
    """
    G√©n√®re le chemin du fichier de log pour un type donn√©.

    Args:
        log_type (str): type de log ('errors', 'events', 'summary', etc.)
        timestamp (str): timestamp de la simulation (format YYYYMMDD_HHMMSS)
        base_dir (str): r√©pertoire racine des logs

    Returns:
        str: chemin complet du fichier log
    """
    folder = os.path.join(base_dir, f'simulated_{timestamp}')
    os.makedirs(folder, exist_ok=True)
    import logging
    logger = logging.getLogger(__name__)
    logger.warning("[DEPRECATED] Utilisation de get_log_path")
    return os.path.join(folder, f'{log_type}.log')

def ensure_strictly_increasing_timestamps(df, col="timestamp"):
    """
    Corrige les timestamps non strictement croissants :
    - Tri par timestamp si n√©cessaire.
    - D√©calage l√©ger des doublons (ajout de 1ms) pour √©viter les √©galit√©s.
    """
    if not df[col].is_monotonic_increasing:
        print("üîß Correction des timestamps non croissants...")

        # 1. Tri
        df = df.sort_values(by=col).reset_index(drop=True)

        # 2. Correction des √©galit√©s
        timestamps = df[col].values.astype('datetime64[ns]')
        diffs = np.diff(timestamps)

        # D√©tecte les doublons ou √©galit√©s successives
        non_increasing_idx = np.where(diffs <= np.timedelta64(0, 'ns'))[0]
        if len(non_increasing_idx) > 0:
            print(f"‚ö†Ô∏è {len(non_increasing_idx)} timestamps √©gaux ou d√©croissants d√©tect√©s. Application de d√©calages...")
            for idx in non_increasing_idx:
                # D√©cale le timestamp suivant de +1 ms par rapport au pr√©c√©dent
                timestamps[idx + 1] = timestamps[idx] + np.timedelta64(1, 'ms')
            df[col] = timestamps
        else:
            print("‚úÖ Tri suffisant, aucun doublon strict √† corriger.")
    else:
        print("‚úÖ Timestamps d√©j√† strictement croissants.")
    return df


# Nouvelle fonction pour g√©n√©rer le chemin de sortie d'une simulation
def get_simulation_output_dir(timestamp, base_dir="data/simulations"):
    """
    G√©n√®re le chemin complet du r√©pertoire de sortie pour une simulation.

    Args:
        timestamp (str): timestamp de la simulation (format YYYYMMDD_HHMMSS)
        base_dir (str): r√©pertoire racine de sortie

    Returns:
        str: chemin du r√©pertoire simulation complet
    """
    output_dir = os.path.join(base_dir, f"simulated_{timestamp}")
    os.makedirs(output_dir, exist_ok=True)
    return output_dir

# Nouvelle fonction pour obtenir le dernier dossier de simulation
def get_latest_simulation_dir(base_dir='data/simulations'):
    """
    Retourne le chemin complet du dernier dossier de simulation dans base_dir.
    """
    if not os.path.exists(base_dir):
        return None
    out_dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]
    if not out_dirs:
        return None
    latest_dir = max(out_dirs, key=lambda d: os.path.getmtime(os.path.join(base_dir, d)))
    return os.path.join(base_dir, latest_dir)

def save_dataframe_as_csv(df, filename):
    """
    Enregistre un DataFrame au format CSV avec colonnes ordonn√©es.
    """
    # Ajouter les colonnes manquantes avec NaN
    for col in CSV_COLUMNS:
        if col not in df.columns:
            df[col] = np.nan
    df_ordered = ensure_csv_column_order(df)
    df_ordered.to_csv(filename, index=False)
    print(f"‚úÖ Fichier CSV sauvegard√© : {filename}")
